<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Kaggle入门(1)--Titanic</title>
    <url>/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/</url>
    <content><![CDATA[<p><code>Kaggle</code>是一个举办机器学习竞赛、托管数据库、编写和分享代码的平台。在这里可以学到很多数据科学的相关知识以及知识落地。</p>
<p>本次数据挖掘的目的是<code>给出泰坦尼克号上的乘客的信息, 预测乘客是否幸存</code></p>
<center>本文参考自 https://cloud.tencent.com/developer/article/1063994 </center>

<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><p>数据来源 : <code>https://www.kaggle.com/c/titanic/data</code><br>平台 : Python<br>涉及到的库 : <code>sklearn</code>, <code>numpy</code>, <code>seaborn</code>, <code>pandas</code>, …</p>
<h2 id="数据获取方法"><a href="#数据获取方法" class="headerlink" title="数据获取方法"></a>数据获取方法</h2><h3 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h3><p>网页下载，解压。</p>
<h3 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h3><p>使用<code>kaggle api</code>, <code>Github</code>地址<code>https://github.com/Kaggle/kaggle-api</code><br>安装方法 : <code>pip install kaggle</code><br>使用方法 : <code>kaggle competitions download -c titanic</code></p>
<a id="more"></a>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><p>Titanic 生存模型预测，其中包含了两组数据：train.csv 和 test.csv，分别为训练集合和测试集合。</p>
<h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">'ignore'</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data = pd.read_csv(<span class="hljs-string">'train.csv'</span>)<br>test_data = pd.read_csv(<span class="hljs-string">'test.csv'</span>)<br></code></pre></td></tr></table></figure>

<h3 id="数据类型与特征信息概览"><a href="#数据类型与特征信息概览" class="headerlink" title="数据类型与特征信息概览"></a>数据类型与特征信息概览</h3><ol>
<li><p>预览<code>train.csv</code>的前几行数据并了解每一个<code>feature</code>的意义, 观察前几行的源数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">sns.set_style(<span class="hljs-string">'whitegrid'</span>)<br>train_data.head()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/train_data_head.png" alt="avatar"></p>
</li>
<li><p>每维<code>feature</code>的<code>info</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data.info()<br>print(<span class="hljs-string">"-"</span> * <span class="hljs-number">40</span>)<br>test_data.info()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/train_test_info.png" alt="avatar"><br>从上面我们可以看出，Age、Cabin、Embarked、Fare几个特征存在缺失值。</p>
</li>
<li><p>绘制存活的比例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data[<span class="hljs-string">'Survived'</span>].value_counts().plot.pie(autopct = <span class="hljs-string">'%1.2f%%'</span>)<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Survived_value_counts.png" alt="avatar"></p>
</li>
</ol>
<h3 id="缺失值处理方法"><a href="#缺失值处理方法" class="headerlink" title="缺失值处理方法"></a>缺失值处理方法</h3><p>有一部分的机器学习算法对缺失值比较敏感<br>处理方法有如下几种</p>
<ol>
<li>如果数据集很多，但有很少的缺失值，可以删掉带缺失值的行</li>
<li>如果该属性相对学习来说不是很重要，可以对缺失值赋均值或者众数。比如在哪儿上船<code>Embarked</code>这一属性(共有三个上船地点)，缺失俩值，可以用众数赋值<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data.Embarked[train_data.Embarked.isnull()] = train_data.Embarked.dropna().mode().values<br></code></pre></td></tr></table></figure></li>
<li>对于标称属性，可以赋一个代表缺失的值，比如’U0’。因为缺失本身也可能代表着一些隐含信息。比如船舱号<code>Cabin</code>这一属性，缺失可能代表并没有船舱<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#replace missing value with U0</span><br>train_data[<span class="hljs-string">'Cabin'</span>] = train_data.Cabin.fillna(<span class="hljs-string">'U0'</span>) <span class="hljs-comment"># train_data.Cabin[train_data.Cabin.isnull()]='U0'</span><br></code></pre></td></tr></table></figure></li>
<li>使用<code>回归</code>、<code>随机森林</code>等模型来预测缺失属性的值<br>因为<code>Age</code>在该数据集里是一个相当重要的特征(先对Age进行分析即可得知)，所以保证一定的缺失值填充准确率是非常重要的，对结果也会产生较大影响。<br>一般情况下，会使用数据完整的条目作为模型的训练集，以此来预测缺失值。<br>对于当前的这个数据，可以使用<code>随机森林</code>来预测也可以使用<code>线性回归</code>预测。<br>这里使用<code>随机森林</code>预测模型，选取数据集中的数值属性作为特征。<br>因为<code>sklearn</code>的模型只能处理<code>数值属性</code>，所以这里先仅选取数值特征，但在实际的应用中需要将非数值特征转换为数值特征。<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestRegressor<br><br><span class="hljs-comment">#choose training data to predict age</span><br>age_df = train_data[[<span class="hljs-string">'Age'</span>,<span class="hljs-string">'Survived'</span>,<span class="hljs-string">'Fare'</span>, <span class="hljs-string">'Parch'</span>, <span class="hljs-string">'SibSp'</span>, <span class="hljs-string">'Pclass'</span>]]<br>age_df_notnull = age_df.loc[(train_data[<span class="hljs-string">'Age'</span>].notnull())]<br>age_df_isnull = age_df.loc[(train_data[<span class="hljs-string">'Age'</span>].isnull())]<br>X = age_df_notnull.values[:,<span class="hljs-number">1</span>:]<br>Y = age_df_notnull.values[:,<span class="hljs-number">0</span>]<br><span class="hljs-comment"># use RandomForestRegression to train data</span><br>RFR = RandomForestRegressor(n_estimators=<span class="hljs-number">1000</span>, n_jobs=<span class="hljs-number">-1</span>)<br>RFR.fit(X,Y)<br>predictAges = RFR.predict(age_df_isnull.values[:,<span class="hljs-number">1</span>:])<br>train_data.loc[train_data[<span class="hljs-string">'Age'</span>].isnull(), [<span class="hljs-string">'Age'</span>]]= predictAges<br></code></pre></td></tr></table></figure>
再来看一下缺失数据处理后的DataFram<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data.info()<br></code></pre></td></tr></table></figure>
<img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/train_data_info.png" alt="avatar"></li>
</ol>
<h3 id="分析数据关系"><a href="#分析数据关系" class="headerlink" title="分析数据关系"></a>分析数据关系</h3><h4 id="性别与是否生存的关系-Sex"><a href="#性别与是否生存的关系-Sex" class="headerlink" title="性别与是否生存的关系 Sex"></a>性别与是否生存的关系 <code>Sex</code></h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data.groupby([<span class="hljs-string">'Sex'</span>,<span class="hljs-string">'Survived'</span>])[<span class="hljs-string">'Survived'</span>].count()<br>train_data[[<span class="hljs-string">'Sex'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Sex'</span>]).mean().plot.bar()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Sex_Survived1.png" alt="avatar"><br><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Sex_Survived2.png" alt="avatar"></p>
<p>以上为不同性别的生存率，可见在泰坦尼克号事故中, 体现了<code>Lady First</code>!</p>
<h4 id="船舱等级和生存与否的关系-Pclass"><a href="#船舱等级和生存与否的关系-Pclass" class="headerlink" title="船舱等级和生存与否的关系 Pclass"></a>船舱等级和生存与否的关系 <code>Pclass</code></h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data.groupby([<span class="hljs-string">'Pclass'</span>,<span class="hljs-string">'Survived'</span>])[<span class="hljs-string">'Pclass'</span>].count()<br>train_data[[<span class="hljs-string">'Pclass'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Pclass'</span>]).mean().plot.bar()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Pclass_Survived1.png" alt="avatar"><br><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Pclass_Survived2.png" alt="avatar"></p>
<p><code>不同等级船舱的男女生存率</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data[[<span class="hljs-string">'Sex'</span>,<span class="hljs-string">'Pclass'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Pclass'</span>,<span class="hljs-string">'Sex'</span>]).mean().plot.bar()<br>train_data.groupby([<span class="hljs-string">'Sex'</span>, <span class="hljs-string">'Pclass'</span>, <span class="hljs-string">'Survived'</span>])[<span class="hljs-string">'Survived'</span>].count()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Sex_Pclass_Survived1.png" alt="avatar"><br><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Sex_Pclass_Survived2.png" alt="avatar"></p>
<h4 id="年龄与存活与否的关系-Age"><a href="#年龄与存活与否的关系-Age" class="headerlink" title="年龄与存活与否的关系 Age"></a>年龄与存活与否的关系 <code>Age</code></h4><h5 id="分别分析不同等级船舱和不同性别下的年龄分布和生存的关系"><a href="#分别分析不同等级船舱和不同性别下的年龄分布和生存的关系" class="headerlink" title="分别分析不同等级船舱和不同性别下的年龄分布和生存的关系"></a>分别分析不同等级船舱和不同性别下的年龄分布和生存的关系</h5><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">fig, ax = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize = (<span class="hljs-number">18</span>, <span class="hljs-number">8</span>))<br>sns.violinplot(<span class="hljs-string">"Pclass"</span>, <span class="hljs-string">"Age"</span>, hue=<span class="hljs-string">"Survived"</span>, data=train_data, split=<span class="hljs-literal">True</span>, ax=ax[<span class="hljs-number">0</span>])<br>ax[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">'Pclass and Age vs Survived'</span>)<br>ax[<span class="hljs-number">0</span>].set_yticks(range(<span class="hljs-number">0</span>, <span class="hljs-number">110</span>, <span class="hljs-number">10</span>))<br><br>sns.violinplot(<span class="hljs-string">"Sex"</span>, <span class="hljs-string">"Age"</span>, hue=<span class="hljs-string">"Survived"</span>, data=train_data, split=<span class="hljs-literal">True</span>, ax=ax[<span class="hljs-number">1</span>])<br>ax[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">'Sex and Age vs Survived'</span>)<br>ax[<span class="hljs-number">1</span>].set_yticks(range(<span class="hljs-number">0</span>, <span class="hljs-number">110</span>, <span class="hljs-number">10</span>))<br><br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Age_Survived1.png" alt="avatar"></p>
<h5 id="分析总体的年龄分布"><a href="#分析总体的年龄分布" class="headerlink" title="分析总体的年龄分布"></a>分析总体的年龄分布</h5><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">5</span>))<br>plt.subplot(<span class="hljs-number">121</span>)<br>train_data[<span class="hljs-string">'Age'</span>].hist(bins=<span class="hljs-number">70</span>)<br>plt.xlabel(<span class="hljs-string">'Age'</span>)<br>plt.ylabel(<span class="hljs-string">'Num'</span>)<br><br>plt.subplot(<span class="hljs-number">122</span>)<br>train_data.boxplot(column=<span class="hljs-string">'Age'</span>, showfliers=<span class="hljs-literal">False</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Age_Survived2.png" alt="avatar"></p>
<h5 id="不同年龄下的生存和非生存的分布情况"><a href="#不同年龄下的生存和非生存的分布情况" class="headerlink" title="不同年龄下的生存和非生存的分布情况"></a>不同年龄下的生存和非生存的分布情况</h5><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">facet = sns.FacetGrid(train_data, hue=<span class="hljs-string">"Survived"</span>,aspect=<span class="hljs-number">4</span>)<br>facet.map(sns.kdeplot,<span class="hljs-string">'Age'</span>,shade= <span class="hljs-literal">True</span>)<br>facet.set(xlim=(<span class="hljs-number">0</span>, train_data[<span class="hljs-string">'Age'</span>].max()))<br>facet.add_legend()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Age_Survived3.png" alt="avatar"></p>
<h5 id="不同年龄下的平均生存率"><a href="#不同年龄下的平均生存率" class="headerlink" title="不同年龄下的平均生存率"></a>不同年龄下的平均生存率</h5><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># average survived passengers by age</span><br>fig, axis1 = plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,figsize=(<span class="hljs-number">18</span>,<span class="hljs-number">4</span>))<br>train_data[<span class="hljs-string">"Age_int"</span>] = train_data[<span class="hljs-string">"Age"</span>].astype(int)<br>average_age = train_data[[<span class="hljs-string">"Age_int"</span>, <span class="hljs-string">"Survived"</span>]].groupby([<span class="hljs-string">'Age_int'</span>],as_index=<span class="hljs-literal">False</span>).mean()<br>sns.barplot(x=<span class="hljs-string">'Age_int'</span>, y=<span class="hljs-string">'Survived'</span>, data=average_age)<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Age_Survived4.png" alt="avatar"></p>
<h5 id="按照年龄，将乘客划分为儿童、少年、成年和老年，分析四个群体的生还情况"><a href="#按照年龄，将乘客划分为儿童、少年、成年和老年，分析四个群体的生还情况" class="headerlink" title="按照年龄，将乘客划分为儿童、少年、成年和老年，分析四个群体的生还情况"></a>按照年龄，将乘客划分为儿童、少年、成年和老年，分析四个群体的生还情况</h5><p>样本有891，平均年龄约为30岁，标准差13.5岁，最小年龄为0.42，最大年龄80</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data[<span class="hljs-string">'Age'</span>].describe()<br><br>bins = [<span class="hljs-number">0</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">65</span>, <span class="hljs-number">100</span>]<br>train_data[<span class="hljs-string">'Age_group'</span>] = pd.cut(train_data[<span class="hljs-string">'Age'</span>], bins)<br>by_age = train_data.groupby(<span class="hljs-string">'Age_group'</span>)[<span class="hljs-string">'Survived'</span>].mean()<br>by_age<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Age_Survived5.png" alt="avatar"><br><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Age_Survived6.png" alt="avatar"><br><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Age_Survived7.png" alt="avatar"></p>
<h4 id="称呼与存活与否的关系-Name"><a href="#称呼与存活与否的关系-Name" class="headerlink" title="称呼与存活与否的关系 Name"></a>称呼与存活与否的关系 <code>Name</code></h4><h5 id="通过观察名字数据，我们可以看出其中包括对乘客的称呼。称呼信息包含了乘客的年龄、性别，同时也包含了如社会地位等的信息。"><a href="#通过观察名字数据，我们可以看出其中包括对乘客的称呼。称呼信息包含了乘客的年龄、性别，同时也包含了如社会地位等的信息。" class="headerlink" title="通过观察名字数据，我们可以看出其中包括对乘客的称呼。称呼信息包含了乘客的年龄、性别，同时也包含了如社会地位等的信息。"></a>通过观察名字数据，我们可以看出其中包括对乘客的称呼。称呼信息包含了乘客的年龄、性别，同时也包含了如社会地位等的信息。</h5><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data[<span class="hljs-string">'Title'</span>] = train_data[<span class="hljs-string">'Name'</span>].str.extract(<span class="hljs-string">' ([A-Za-z]+)\.'</span>, expand=<span class="hljs-literal">False</span>)<br>pd.crosstab(train_data[<span class="hljs-string">'Title'</span>], train_data[<span class="hljs-string">'Sex'</span>])<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Name_List.png" alt="avatar"></p>
<h5 id="观察不同称呼与生存率的关系"><a href="#观察不同称呼与生存率的关系" class="headerlink" title="观察不同称呼与生存率的关系"></a>观察不同称呼与生存率的关系</h5><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data[[<span class="hljs-string">'Title'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Title'</span>]).mean().plot.bar()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Name_Survived.png" alt="avatar"></p>
<h5 id="观察名字长度和生存率之间存在关系的可能"><a href="#观察名字长度和生存率之间存在关系的可能" class="headerlink" title="观察名字长度和生存率之间存在关系的可能"></a>观察名字长度和生存率之间存在关系的可能</h5><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">fig, axis1 = plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,figsize=(<span class="hljs-number">18</span>,<span class="hljs-number">4</span>))<br>train_data[<span class="hljs-string">'Name_length'</span>] = train_data[<span class="hljs-string">'Name'</span>].apply(len)<br>name_length = train_data[[<span class="hljs-string">'Name_length'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Name_length'</span>],as_index=<span class="hljs-literal">False</span>).mean()<br>sns.barplot(x=<span class="hljs-string">'Name_length'</span>, y=<span class="hljs-string">'Survived'</span>, data=name_length)<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Name_Length_Survived.png" alt="avatar"><br>从上面的图片可以看出，名字长度和生存与否确实也存在一定的相关性。</p>
<h4 id="有无兄弟姐妹和存活与否的关系-SibSp"><a href="#有无兄弟姐妹和存活与否的关系-SibSp" class="headerlink" title="有无兄弟姐妹和存活与否的关系 SibSp"></a>有无兄弟姐妹和存活与否的关系 <code>SibSp</code></h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将数据分为有兄弟姐妹的和没有兄弟姐妹的两组：</span><br>sibsp_df = train_data[train_data[<span class="hljs-string">'SibSp'</span>] != <span class="hljs-number">0</span>]<br>no_sibsp_df = train_data[train_data[<span class="hljs-string">'SibSp'</span>] == <span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))<br>plt.subplot(<span class="hljs-number">121</span>)<br>sibsp_df[<span class="hljs-string">'Survived'</span>].value_counts().plot.pie(labels=[<span class="hljs-string">'No Survived'</span>, <span class="hljs-string">'Survived'</span>], autopct = <span class="hljs-string">'%1.1f%%'</span>)<br>plt.xlabel(<span class="hljs-string">'sibsp'</span>)<br><br>plt.subplot(<span class="hljs-number">122</span>)<br>no_sibsp_df[<span class="hljs-string">'Survived'</span>].value_counts().plot.pie(labels=[<span class="hljs-string">'No Survived'</span>, <span class="hljs-string">'Survived'</span>], autopct = <span class="hljs-string">'%1.1f%%'</span>)<br>plt.xlabel(<span class="hljs-string">'no_sibsp'</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/SibSp_Survived.png" alt="avatar"></p>
<h4 id="有无父母子女和存活与否的关系-Parch"><a href="#有无父母子女和存活与否的关系-Parch" class="headerlink" title="有无父母子女和存活与否的关系 Parch"></a>有无父母子女和存活与否的关系 <code>Parch</code></h4><p>和有无兄弟姐妹一样，同样分析可以得到</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">parch_df = train_data[train_data[<span class="hljs-string">'Parch'</span>] != <span class="hljs-number">0</span>]<br>no_parch_df = train_data[train_data[<span class="hljs-string">'Parch'</span>] == <span class="hljs-number">0</span>]<br><br>plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))<br>plt.subplot(<span class="hljs-number">121</span>)<br>parch_df[<span class="hljs-string">'Survived'</span>].value_counts().plot.pie(labels=[<span class="hljs-string">'No Survived'</span>, <span class="hljs-string">'Survived'</span>], autopct = <span class="hljs-string">'%1.1f%%'</span>)<br>plt.xlabel(<span class="hljs-string">'parch'</span>)<br><br>plt.subplot(<span class="hljs-number">122</span>)<br>no_parch_df[<span class="hljs-string">'Survived'</span>].value_counts().plot.pie(labels=[<span class="hljs-string">'No Survived'</span>, <span class="hljs-string">'Survived'</span>], autopct = <span class="hljs-string">'%1.1f%%'</span>)<br>plt.xlabel(<span class="hljs-string">'no_parch'</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Parch_Survived.png" alt="avatar"></p>
<h4 id="亲友的人数和存活与否的关系-SibSp-amp-Parch"><a href="#亲友的人数和存活与否的关系-SibSp-amp-Parch" class="headerlink" title="亲友的人数和存活与否的关系 SibSp &amp; Parch"></a>亲友的人数和存活与否的关系 <code>SibSp &amp; Parch</code></h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">fig,ax=plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,figsize=(<span class="hljs-number">18</span>,<span class="hljs-number">8</span>))<br>train_data[[<span class="hljs-string">'Parch'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Parch'</span>]).mean().plot.bar(ax=ax[<span class="hljs-number">0</span>])<br>ax[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">'Parch and Survived'</span>)<br>train_data[[<span class="hljs-string">'SibSp'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'SibSp'</span>]).mean().plot.bar(ax=ax[<span class="hljs-number">1</span>])<br>ax[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">'SibSp and Survived'</span>)<br><br>train_data[<span class="hljs-string">'Family_Size'</span>] = train_data[<span class="hljs-string">'Parch'</span>] + train_data[<span class="hljs-string">'SibSp'</span>] + <span class="hljs-number">1</span><br>train_data[[<span class="hljs-string">'Family_Size'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Family_Size'</span>]).mean().plot.bar()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/SibSp_Parch_Survived.png" alt="avatar"><br><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Family_Size_Survived.png" alt="avatar"><br>从图表中可以看出，若独自一人，那么其存活率比较低；但是如果亲友太多的话，存活率也会很低。</p>
<h4 id="票价分布和存活与否的关系-Fare"><a href="#票价分布和存活与否的关系-Fare" class="headerlink" title="票价分布和存活与否的关系 Fare"></a>票价分布和存活与否的关系 <code>Fare</code></h4><p>首先绘制票价的分布情况</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))<br>train_data[<span class="hljs-string">'Fare'</span>].hist(bins = <span class="hljs-number">70</span>)<br><br>train_data.boxplot(column=<span class="hljs-string">'Fare'</span>, by=<span class="hljs-string">'Pclass'</span>, showfliers=<span class="hljs-literal">False</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Fare_dis1.png" alt="avatar"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_data[<span class="hljs-string">'Fare'</span>].describe()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Fare_describe.png" alt="avatar"></p>
<p>绘制生存与否与票价均值和方差的关系</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">fare_not_survived = train_data[<span class="hljs-string">'Fare'</span>][train_data[<span class="hljs-string">'Survived'</span>] == <span class="hljs-number">0</span>]<br>fare_survived = train_data[<span class="hljs-string">'Fare'</span>][train_data[<span class="hljs-string">'Survived'</span>] == <span class="hljs-number">1</span>]<br><br>average_fare = pd.DataFrame([fare_not_survived.mean(), fare_survived.mean()])<br>std_fare = pd.DataFrame([fare_not_survived.std(), fare_survived.std()])<br>average_fare.plot(yerr=std_fare, kind=<span class="hljs-string">'bar'</span>, legend=<span class="hljs-literal">False</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Fare_Var.png" alt="avatar"><br>由上图标可知，票价与是否生还有一定的相关性，生还者的平均票价要大于未生还者的平均票价。</p>
<h4 id="船舱类型和存活与否的关系-Cabin"><a href="#船舱类型和存活与否的关系-Cabin" class="headerlink" title="船舱类型和存活与否的关系 Cabin"></a>船舱类型和存活与否的关系 <code>Cabin</code></h4><p>由于船舱的缺失值确实太多，有效值仅仅有204个，很难分析出不同的船舱和存活的关系，所以在做特征工程的时候，可以直接将该组特征<code>丢弃</code>。<br>简单地将数据分为是否有Cabin记录作为特征，与生存与否进行分析。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Replace missing values with "U0"</span><br>train_data.loc[train_data.Cabin.isnull(), <span class="hljs-string">'Cabin'</span>] = <span class="hljs-string">'U0'</span><br>train_data[<span class="hljs-string">'Has_Cabin'</span>] = train_data[<span class="hljs-string">'Cabin'</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> x == <span class="hljs-string">'U0'</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>)<br>train_data[[<span class="hljs-string">'Has_Cabin'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'Has_Cabin'</span>]).mean().plot.bar()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Has_Cabin.png" alt="avatar"><br>对不同类型的船舱进行分析</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># create feature for the alphabetical part of the cabin number</span><br>train_data[<span class="hljs-string">'CabinLetter'</span>] = train_data[<span class="hljs-string">'Cabin'</span>].map(<span class="hljs-keyword">lambda</span> x: re.compile(<span class="hljs-string">"([a-zA-Z]+)"</span>).search(x).group())<br><span class="hljs-comment"># convert the distinct cabin letters with incremental integer values</span><br>train_data[<span class="hljs-string">'CabinLetter'</span>] = pd.factorize(train_data[<span class="hljs-string">'CabinLetter'</span>])[<span class="hljs-number">0</span>]<br>train_data[[<span class="hljs-string">'CabinLetter'</span>,<span class="hljs-string">'Survived'</span>]].groupby([<span class="hljs-string">'CabinLetter'</span>]).mean().plot.bar()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Cabin_Letter.png" alt="avatar"><br>可见，不同的船舱生存率也有不同，但是差别不大。所以在处理中，我们可以直接将特征删除。</p>
<h4 id="港口和存活与否的关系-Embarked"><a href="#港口和存活与否的关系-Embarked" class="headerlink" title="港口和存活与否的关系 Embarked"></a>港口和存活与否的关系 <code>Embarked</code></h4><p>泰坦尼克号从英国的南安普顿港出发，途径法国瑟堡和爱尔兰昆士敦，那么在昆士敦之前上船的人，有可能在瑟堡或昆士敦下船，这些人将不会遇到海难。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">sns.countplot(<span class="hljs-string">'Embarked'</span>, hue=<span class="hljs-string">'Survived'</span>, data=train_data)<br>plt.title(<span class="hljs-string">'Embarked and Survived'</span>)<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Embarked.png" alt="avatar"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">sns.factorplot(<span class="hljs-string">'Embarked'</span>, <span class="hljs-string">'Survived'</span>, data=train_data, size=<span class="hljs-number">3</span>, aspect=<span class="hljs-number">2</span>)<br>plt.title(<span class="hljs-string">'Embarked and Survived rate'</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Embarked2.png" alt="avatar"><br>由上可以看出，在不同的港口上船，生还率不同，C最高，Q次之，S最低。<br><strong>以上为所给出的数据特征与生还与否的分析</strong><br>据了解，泰坦尼克号上共有2224名乘客。本训练数据只给出了891名乘客的信息，如果该数据集是从总共的2224人中随机选出的，根据中心极限定理，该样本的数据也足够大，那么我们的分析结果就具有代表性；但如果不是随机选取，那么我们的分析结果就可能不太靠谱了。</p>
<h4 id="其他可能和存活与否有关系的特征"><a href="#其他可能和存活与否有关系的特征" class="headerlink" title="其他可能和存活与否有关系的特征"></a>其他可能和存活与否有关系的特征</h4><p>对于数据集中没有给出的特征信息，我们还可以联想其他可能会对模型产生影响的特征因素。如：乘客的国籍、乘客的身高、乘客的体重、乘客是否会游泳、乘客职业等等。</p>
<p>另外还有数据集中没有分析的几个特征：<code>Ticket（船票号）</code>、<code>Cabin（船舱号）</code>,这些因素的不同可能会影响乘客在船中的位置从而影响<code>逃生的顺序</code>。但是船舱号数据缺失，船票号类别大，难以分析规律，所以在后期模型融合的时候，将这些因素交由模型来决定其重要性。</p>
<h3 id="变量转换"><a href="#变量转换" class="headerlink" title="变量转换"></a>变量转换</h3><p>变量转换的目的是将数据转换为适用于模型使用的数据，不同模型接受不同类型的数据，<code>Scikit-learn</code>要求数据都是数字型<code>numeric</code>，所以我们要将一些<code>非数字型</code>的原始数据转换为<code>数字型numeric</code>。</p>
<p>所以下面对数据的转换进行介绍，以在进行特征工程的时候使用。</p>
<p>所有的数据可以分为两类：</p>
<ol>
<li>定量(Quantitative)变量可以以某种方式排序，<code>Age</code>就是一个很好的例子。</li>
<li>定性(Qualitative)变量描述了物体的某一（不能被数学表示的）方面，<code>Embarked</code>就是一个例子。</li>
</ol>
<h4 id="定性-Qualitative-转换"><a href="#定性-Qualitative-转换" class="headerlink" title="定性(Qualitative)转换"></a>定性(Qualitative)转换</h4><h5 id="Dummy-Variables"><a href="#Dummy-Variables" class="headerlink" title="Dummy Variables"></a>Dummy Variables</h5><p>就是类别变量或者二元变量，当qualitative variable是一些频繁出现的几个独立变量时，Dummy Variables比较适合使用。我们以Embarked为例，Embarked只包含三个值’S’,’C’,’Q’，我们可以使用下面的代码将其转换为dummies:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">embark_dummies  = pd.get_dummies(train_data[<span class="hljs-string">'Embarked'</span>])<br>train_data = train_data.join(embark_dummies)<br>train_data.drop([<span class="hljs-string">'Embarked'</span>], axis=<span class="hljs-number">1</span>,inplace=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">embark_dummies = train_data[[<span class="hljs-string">'S'</span>, <span class="hljs-string">'C'</span>, <span class="hljs-string">'Q'</span>]]<br>embark_dummies.head()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/embark_dummies.png" alt="avatar"></p>
<h5 id="Factorizing"><a href="#Factorizing" class="headerlink" title="Factorizing"></a>Factorizing</h5><p><code>dummy</code>不好处理<code>Cabin（船舱号）</code>这种<code>标称</code>属性，因为他出现的变量比较多。所以Pandas有一个方法叫做<code>factorize()</code>，它可以<strong>创建一些数字，来表示类别变量，对每一个类别映射一个ID，这种映射最后只生成一个特征</strong>，不像dummy那样生成多个特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Replace missing values with "U0"</span><br>train_data[<span class="hljs-string">'Cabin'</span>][train_data.Cabin.isnull()] = <span class="hljs-string">'U0'</span><br><span class="hljs-comment"># create feature for the alphabetical part of the cabin number</span><br>train_data[<span class="hljs-string">'CabinLetter'</span>] = train_data[<span class="hljs-string">'Cabin'</span>].map( <span class="hljs-keyword">lambda</span> x : re.compile(<span class="hljs-string">"([a-zA-Z]+)"</span>).search(x).group())<br><span class="hljs-comment"># convert the distinct cabin letters with incremental integer values</span><br>train_data[<span class="hljs-string">'CabinLetter'</span>] = pd.factorize(train_data[<span class="hljs-string">'CabinLetter'</span>])[<span class="hljs-number">0</span>]<br><br>train_data[<span class="hljs-string">'CabinLetter'</span>].head()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/CabinLetter.png" alt="avatar"></p>
<h4 id="定量-Quantitative-转换"><a href="#定量-Quantitative-转换" class="headerlink" title="定量(Quantitative)转换"></a>定量(Quantitative)转换</h4><h5 id="Scaling"><a href="#Scaling" class="headerlink" title="Scaling"></a>Scaling</h5><p>Scaling可以<strong>将一个很大范围的数值映射到一个很小的范围</strong>(通常是-1 - 1，或则是0 - 1)，很多情况下我们需要将数值做Scaling使其<strong>范围大小一样</strong>，否则大范围数值特征将会由更高的权重。比如：Age的范围可能只是0-100，而income的范围可能是0-10000000，在某些对数组大小敏感的模型中会影响其结果。</p>
<p>下面对Age进行Scaling</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br><br><span class="hljs-keyword">assert</span> np.size(train_data[<span class="hljs-string">'Age'</span>]) == <span class="hljs-number">891</span><br><span class="hljs-comment"># StandardScaler will subtract the mean from each value then scale to the unit variance</span><br>scaler = preprocessing.StandardScaler()<br>train_data[<span class="hljs-string">'Age_scaled'</span>] = scaler.fit_transform(train_data[<span class="hljs-string">'Age'</span>].values.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>))<br><br>train_data[<span class="hljs-string">'Age_scaled'</span>].head()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Scale_Age.png" alt="avatar"></p>
<h5 id="Binning"><a href="#Binning" class="headerlink" title="Binning"></a>Binning</h5><p>Binning通过观察“邻居”(即周围的值)<strong>将连续数据离散化</strong>。存储的值被分布到一些“桶”或“箱“”中，就像直方图的bin将数据划分成几块一样。下面的代码对Fare进行Binning。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Divide all fares into quartiles</span><br>train_data[<span class="hljs-string">'Fare_bin'</span>] = pd.qcut(train_data[<span class="hljs-string">'Fare'</span>], <span class="hljs-number">5</span>)<br>train_data[<span class="hljs-string">'Fare_bin'</span>].head()<br></code></pre></td></tr></table></figure>
<p><img src="/2019/04/09/Kaggle%E5%85%A5%E9%97%A8-1-Titanic/Bin_Fare.png" alt="avatar"><br>在将数据Bining化后，要么将数据factorize化，要么dummies化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># qcut() creates a new variable that identifies the quartile range, but we can't use the string</span><br><span class="hljs-comment"># so either factorize or create dummies from the result</span><br><br><span class="hljs-comment"># factorize</span><br>train_data[<span class="hljs-string">'Fare_bin_id'</span>] = pd.factorize(train_data[<span class="hljs-string">'Fare_bin'</span>])[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># dummies</span><br>fare_bin_dummies_df = pd.get_dummies(train_data[<span class="hljs-string">'Fare_bin'</span>]).rename(columns=<span class="hljs-keyword">lambda</span> x: <span class="hljs-string">'Fare_'</span> + str(x))<br>train_data = pd.concat([train_data, fare_bin_dummies_df], axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><p>在进行特征工程的时候，我们不仅需要对训练数据进行处理，还需要同时<strong>将测试数据同训练数据一起处理</strong>，使得二者具有相同的数据类型和数据分布。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_df_org = pd.read_csv(<span class="hljs-string">'train.csv'</span>)<br>test_df_org = pd.read_csv(<span class="hljs-string">'test.csv'</span>)<br>test_df_org[<span class="hljs-string">'Survived'</span>] = <span class="hljs-number">0</span><br>combined_train_test = train_df_org.append(test_df_org)<br>PassengerId = test_df_org[<span class="hljs-string">'PassengerId'</span>]<br></code></pre></td></tr></table></figure>
<p>对数据进行特征工程，也就是从各项参数中提取出对输出结果有或大或小的影响的特征，将这些特征作为训练模型的依据。</p>
<p>一般来说，我们会先从含有缺失值的特征开始。</p>
<h4 id="Embarked"><a href="#Embarked" class="headerlink" title="Embarked"></a>Embarked</h4><p>因为<code>Embarked</code>项的缺失值不多，所以这里我们以<code>众数</code>来填充</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">combined_train_test[<span class="hljs-string">'Embarked'</span>].fillna(combined_train_test[<span class="hljs-string">'Embarked'</span>].mode().iloc[<span class="hljs-number">0</span>], inplace=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>对于三种不同的港口，由上面介绍的数值转换，我们知道可以有两种特征处理方式：dummy和facrorizing。因为只有三个港口，所以我们可以直接用dummy来处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 为了后面的特征分析，这里我们将 Embarked 特征进行facrorizing</span><br>combined_train_test[<span class="hljs-string">'Embarked'</span>] = pd.factorize(combined_train_test[<span class="hljs-string">'Embarked'</span>])[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 使用 pd.get_dummies 获取one-hot 编码</span><br>emb_dummies_df = pd.get_dummies(combined_train_test[<span class="hljs-string">'Embarked'</span>], prefix=combined_train_test[[<span class="hljs-string">'Embarked'</span>]].columns[<span class="hljs-number">0</span>])<br>combined_train_test = pd.concat([combined_train_test, emb_dummies_df], axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Kaggle</tag>
        <tag>Scikit-learn</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow学习笔记(3)</title>
    <url>/2019/04/02/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3/</url>
    <content><![CDATA[<center>使用**Neural Network反向传播算法**实现MNIST手写数字识别</center>

<h2 id="TensorFlow实现Neural-Network反向传播算法"><a href="#TensorFlow实现Neural-Network反向传播算法" class="headerlink" title="TensorFlow实现Neural Network反向传播算法"></a>TensorFlow实现Neural Network反向传播算法</h2><p>数据集前面有说，直接开始建立模型</p>
<h3 id="不含隐层的神经网络-输入层是784个神经元-输出层是10个神经元"><a href="#不含隐层的神经网络-输入层是784个神经元-输出层是10个神经元" class="headerlink" title="不含隐层的神经网络, 输入层是784个神经元, 输出层是10个神经元"></a>不含隐层的神经网络, 输入层是784个神经元, 输出层是10个神经元</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data<br>mnist = input_data.read_data_sets(<span class="hljs-string">"MNIST_data"</span>, one_hot=<span class="hljs-literal">True</span>)<br><br>print(mnist.train.images.shape, mnist.train.labels.shape)<br>print(mnist.test.images.shape, mnist.test.labels.shape)<br>print(mnist.validation.images.shape, mnist.validation.labels.shape)<br>batch_size = <span class="hljs-number">100</span><br>n_batch =  mnist.train.num_examples  // batch_size<br></code></pre></td></tr></table></figure>
<p>其实不含有隐藏层的就是多分类，和前面一样</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">x = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>,<span class="hljs-number">784</span>])<br>y = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>,<span class="hljs-number">10</span>])<br>W = tf.Variable(tf.zeros([<span class="hljs-number">784</span>,<span class="hljs-number">10</span>]))<br>b = tf.Variable(tf.zeros([<span class="hljs-number">1</span>,<span class="hljs-number">10</span>])) <br>prediction = tf.nn.softmax(tf.matmul(x,W)+b)<br>loss = tf.reduce_mean(tf.square(y-prediction))<br>train_step = tf.train.GradientDescentOptimizer(<span class="hljs-number">0.2</span>).minimize(loss)<br>init = tf.global_variables_initializer()<br>correct_prediction = tf.equal(tf.argmax(y,<span class="hljs-number">1</span>), tf.argmax(prediction,<span class="hljs-number">1</span>))<br>accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))<br></code></pre></td></tr></table></figure>
<p>开始训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    sess.run(init)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">200</span>):<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> range(n_batch):<br>            batch_xs,batch_ys = mnist.train.next_batch(batch_size)<br>            sess.run(train_step,feed_dict=&#123;x:batch_xs,y:batch_ys&#125;)<br>        acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images, y:mnist.test.labels&#125;) <br>        <span class="hljs-keyword">print</span> (<span class="hljs-string">"Iter "</span> + str(epoch) + <span class="hljs-string">",Testing Accuracy "</span> + str(acc))<br></code></pre></td></tr></table></figure>
<p>结果如下</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><code class="hljs angelscript">Iter <span class="hljs-number">0</span>,Testing Accuracy <span class="hljs-number">0.8321</span><br>Iter <span class="hljs-number">1</span>,Testing Accuracy <span class="hljs-number">0.8702</span><br>Iter <span class="hljs-number">2</span>,Testing Accuracy <span class="hljs-number">0.8819</span><br>Iter <span class="hljs-number">3</span>,Testing Accuracy <span class="hljs-number">0.8879</span><br>Iter <span class="hljs-number">4</span>,Testing Accuracy <span class="hljs-number">0.8941</span><br>Iter <span class="hljs-number">5</span>,Testing Accuracy <span class="hljs-number">0.8965</span><br>Iter <span class="hljs-number">6</span>,Testing Accuracy <span class="hljs-number">0.9006</span><br>Iter <span class="hljs-number">7</span>,Testing Accuracy <span class="hljs-number">0.9024</span><br>Iter <span class="hljs-number">8</span>,Testing Accuracy <span class="hljs-number">0.9043</span><br>Iter <span class="hljs-number">9</span>,Testing Accuracy <span class="hljs-number">0.905</span><br>...<br>Iter <span class="hljs-number">190</span>,Testing Accuracy <span class="hljs-number">0.9288</span><br>Iter <span class="hljs-number">191</span>,Testing Accuracy <span class="hljs-number">0.9289</span><br>Iter <span class="hljs-number">192</span>,Testing Accuracy <span class="hljs-number">0.9291</span><br>Iter <span class="hljs-number">193</span>,Testing Accuracy <span class="hljs-number">0.929</span><br>Iter <span class="hljs-number">194</span>,Testing Accuracy <span class="hljs-number">0.9289</span><br>Iter <span class="hljs-number">195</span>,Testing Accuracy <span class="hljs-number">0.929</span><br>Iter <span class="hljs-number">196</span>,Testing Accuracy <span class="hljs-number">0.9287</span><br>Iter <span class="hljs-number">197</span>,Testing Accuracy <span class="hljs-number">0.9291</span><br>Iter <span class="hljs-number">198</span>,Testing Accuracy <span class="hljs-number">0.9291</span><br>Iter <span class="hljs-number">199</span>,Testing Accuracy <span class="hljs-number">0.9292</span><br></code></pre></td></tr></table></figure>
<p>Accuracy达到了92%以上。</p>
<h3 id="含一个隐层的神经网络"><a href="#含一个隐层的神经网络" class="headerlink" title="含一个隐层的神经网络"></a>含一个隐层的神经网络</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data<br>mnist = input_data.read_data_sets(<span class="hljs-string">"MNIST_data"</span>, one_hot=<span class="hljs-literal">True</span>)<br><br>print(mnist.train.images.shape, mnist.train.labels.shape)<br>print(mnist.test.images.shape, mnist.test.labels.shape)<br>print(mnist.validation.images.shape, mnist.validation.labels.shape)<br>batch_size = <span class="hljs-number">100</span><br>n_batch =  mnist.train.num_examples // batch_size<br>x = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>,<span class="hljs-number">784</span>])<br>y = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>,<span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>
<p>下面的模型构建有所区别</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">Weights_L1 = tf.Variable(tf.random_normal([<span class="hljs-number">784</span>,<span class="hljs-number">100</span>], stddev=<span class="hljs-number">0.1</span>))<br>biase_L1 = tf.Variable(tf.zeros([<span class="hljs-number">1</span>,<span class="hljs-number">100</span>])) <br>Wx_plus_b_L1 = tf.matmul(x, Weights_L1)+biase_L1 <br>L1 = tf.nn.sigmoid(Wx_plus_b_L1)<br><br>Weights_L2 = tf.Variable(tf.random_normal([<span class="hljs-number">100</span>,<span class="hljs-number">100</span>], stddev=<span class="hljs-number">0.1</span>))<br>biase_L2 = tf.Variable(tf.zeros([<span class="hljs-number">1</span>,<span class="hljs-number">100</span>])) <br>Wx_plus_b_L2 = tf.matmul(L1, Weights_L2)+biase_L2 <br>L2 = tf.nn.sigmoid(Wx_plus_b_L2)<br><br>Weights_L3 = tf.Variable(tf.random_normal([<span class="hljs-number">100</span>,<span class="hljs-number">10</span>], stddev=<span class="hljs-number">0.1</span>))<br>biase_L3 = tf.Variable(tf.zeros([<span class="hljs-number">1</span>,<span class="hljs-number">10</span>]))<br>Wx_plus_b_L3 = tf.matmul(L2,Weights_L3) + biase_L3<br>prediction = tf.nn.sigmoid(Wx_plus_b_L3)<br><br>loss = tf.reduce_mean(tf.square(y-prediction))<br>train_step = tf.train.GradientDescentOptimizer(<span class="hljs-number">0.2</span>).minimize(loss)<br>init = tf.global_variables_initializer()<br>correct_prediction = tf.equal(tf.argmax(y,<span class="hljs-number">1</span>), tf.argmax(prediction,<span class="hljs-number">1</span>))<br>accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))<br></code></pre></td></tr></table></figure>
<p>值得注意的是<code>Weights_L1</code>,<code>Weights_L2</code>,<code>Weights_L3</code>,使用正态分布初始化时，<code>stddev</code>不能太大。</p>
<p>开始训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    sess.run(init)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">200</span>): <br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> range(n_batch):             <br>            batch_xs,batch_ys = mnist.train.next_batch(batch_size)<br>            sess.run(train_step,feed_dict=&#123;x:batch_xs,y:batch_ys&#125;)<br>        acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images, y:mnist.test.labels&#125;) <br>        <span class="hljs-keyword">print</span> (<span class="hljs-string">"Iter "</span> + str(epoch) + <span class="hljs-string">",Testing Accuracy "</span> + str(acc))<br></code></pre></td></tr></table></figure>
<p>结果如下</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><code class="hljs angelscript">Iter <span class="hljs-number">0</span>,Testing Accuracy <span class="hljs-number">0.1198</span><br>Iter <span class="hljs-number">1</span>,Testing Accuracy <span class="hljs-number">0.2264</span><br>Iter <span class="hljs-number">2</span>,Testing Accuracy <span class="hljs-number">0.2752</span><br>Iter <span class="hljs-number">3</span>,Testing Accuracy <span class="hljs-number">0.2504</span><br>Iter <span class="hljs-number">4</span>,Testing Accuracy <span class="hljs-number">0.3793</span><br>Iter <span class="hljs-number">5</span>,Testing Accuracy <span class="hljs-number">0.3175</span><br>Iter <span class="hljs-number">6</span>,Testing Accuracy <span class="hljs-number">0.3746</span><br>Iter <span class="hljs-number">7</span>,Testing Accuracy <span class="hljs-number">0.4038</span><br>Iter <span class="hljs-number">8</span>,Testing Accuracy <span class="hljs-number">0.4134</span><br>Iter <span class="hljs-number">9</span>,Testing Accuracy <span class="hljs-number">0.4354</span><br>Iter <span class="hljs-number">10</span>,Testing Accuracy <span class="hljs-number">0.4994</span><br>Iter <span class="hljs-number">11</span>,Testing Accuracy <span class="hljs-number">0.5342</span><br>Iter <span class="hljs-number">12</span>,Testing Accuracy <span class="hljs-number">0.5724</span><br>Iter <span class="hljs-number">13</span>,Testing Accuracy <span class="hljs-number">0.6077</span><br>Iter <span class="hljs-number">14</span>,Testing Accuracy <span class="hljs-number">0.6575</span><br>Iter <span class="hljs-number">15</span>,Testing Accuracy <span class="hljs-number">0.6749</span><br>Iter <span class="hljs-number">16</span>,Testing Accuracy <span class="hljs-number">0.7026</span><br>Iter <span class="hljs-number">17</span>,Testing Accuracy <span class="hljs-number">0.7267</span><br>Iter <span class="hljs-number">18</span>,Testing Accuracy <span class="hljs-number">0.7541</span><br>Iter <span class="hljs-number">19</span>,Testing Accuracy <span class="hljs-number">0.7596</span><br>Iter <span class="hljs-number">20</span>,Testing Accuracy <span class="hljs-number">0.7759</span><br>Iter <span class="hljs-number">21</span>,Testing Accuracy <span class="hljs-number">0.7895</span><br>Iter <span class="hljs-number">22</span>,Testing Accuracy <span class="hljs-number">0.8028</span><br>...<br>Iter <span class="hljs-number">190</span>,Testing Accuracy <span class="hljs-number">0.94</span><br>Iter <span class="hljs-number">191</span>,Testing Accuracy <span class="hljs-number">0.9401</span><br>Iter <span class="hljs-number">192</span>,Testing Accuracy <span class="hljs-number">0.9399</span><br>Iter <span class="hljs-number">193</span>,Testing Accuracy <span class="hljs-number">0.9399</span><br>Iter <span class="hljs-number">194</span>,Testing Accuracy <span class="hljs-number">0.9404</span><br>Iter <span class="hljs-number">195</span>,Testing Accuracy <span class="hljs-number">0.9406</span><br>Iter <span class="hljs-number">196</span>,Testing Accuracy <span class="hljs-number">0.9401</span><br>Iter <span class="hljs-number">197</span>,Testing Accuracy <span class="hljs-number">0.9409</span><br>Iter <span class="hljs-number">198</span>,Testing Accuracy <span class="hljs-number">0.941</span><br>Iter <span class="hljs-number">199</span>,Testing Accuracy <span class="hljs-number">0.9408</span><br></code></pre></td></tr></table></figure>
<p>Accuracy达到了94%以上，比上一个模型好一些。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>在<code>TensorFlow</code>框架下有许多很方便的函数，但是对于初学者来说，在<code>MATLAB</code>中将这些算法实现一遍有利于掌握反向传播机制。</p>
<h2 id="MATLAB实现Neural-Network反向传播算法"><a href="#MATLAB实现Neural-Network反向传播算法" class="headerlink" title="MATLAB实现Neural Network反向传播算法"></a>MATLAB实现Neural Network反向传播算法</h2><center>以下内容参考Coursera上Machine Learning课后习题</center>

<h3 id="设置参数"><a href="#设置参数" class="headerlink" title="设置参数"></a>设置参数</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab">input_layer_size  = <span class="hljs-number">400</span>;  <span class="hljs-comment">% 20x20 Input Images of Digits</span><br>hidden_layer_size = <span class="hljs-number">25</span>;   <span class="hljs-comment">% 25 hidden units</span><br>num_labels = <span class="hljs-number">10</span>;          <span class="hljs-comment">% 10 labels, from 1 to 10  </span><br>lambda = <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure>
<p>数据是20*20的，隐层有25个神经元，10个类。<br><code>lambda</code>是正则化参数。</p>
<h3 id="Load-Training-Data"><a href="#Load-Training-Data" class="headerlink" title="Load Training Data"></a>Load Training Data</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab">load(<span class="hljs-string">'ex4data1.mat'</span>);<br>m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);<br></code></pre></td></tr></table></figure>

<h3 id="定义CostFunction"><a href="#定义CostFunction" class="headerlink" title="定义CostFunction"></a>定义CostFunction</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[J grad]</span> = <span class="hljs-title">nnCostFunction</span><span class="hljs-params">(nn_params, ...<br>                                   input_layer_size, ...<br>                                   hidden_layer_size, ...<br>                                   num_labels, ...<br>                                   X, y, lambda)</span></span><br><br>Theta1 = <span class="hljs-built_in">reshape</span>(nn_params(<span class="hljs-number">1</span>:hidden_layer_size * (input_layer_size + <span class="hljs-number">1</span>)), ...<br>                 hidden_layer_size, (input_layer_size + <span class="hljs-number">1</span>));<br><br>Theta2 = <span class="hljs-built_in">reshape</span>(nn_params((<span class="hljs-number">1</span> + (hidden_layer_size * (input_layer_size + <span class="hljs-number">1</span>))):<span class="hljs-keyword">end</span>), ...<br>                 num_labels, (hidden_layer_size + <span class="hljs-number">1</span>));<br><br><span class="hljs-comment">% Setup some useful variables</span><br>m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);<br><br>J = <span class="hljs-number">0</span>;<br>Theta1_grad = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(Theta1));<br>Theta2_grad = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(Theta2));<br><br>a1 = [<span class="hljs-built_in">ones</span>(<span class="hljs-built_in">size</span>(X,<span class="hljs-number">1</span>),<span class="hljs-number">1</span>) X];<br>z2 = a1*Theta1';<br>a2 = sigmoid(z2);<br>a2 = [<span class="hljs-built_in">ones</span>(<span class="hljs-built_in">size</span>(a2,<span class="hljs-number">1</span>),<span class="hljs-number">1</span>) a2];<br>z3 = Theta2*a2';<br>a3 = sigmoid(z3);<br><br><span class="hljs-keyword">for</span> k = <span class="hljs-number">1</span>:num_labels<br>    J = J - <span class="hljs-built_in">log</span>(a3(k,:))*(y==k) - <span class="hljs-built_in">log</span>(<span class="hljs-number">1</span>-a3(k,:))*(<span class="hljs-number">1</span>-(y==k));<br><span class="hljs-keyword">end</span><br><br>SumSquare1 = sum(Theta1.^<span class="hljs-number">2</span>);<br>SumSquare2 = sum(Theta2.^<span class="hljs-number">2</span>);<br>J = J + (sum(SumSquare1(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>)) + sum(SumSquare2(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>))) * lambda / <span class="hljs-number">2</span>;<br>J = J / m;<br><br><span class="hljs-comment">% backforward</span><br>EYE = <span class="hljs-built_in">eye</span>(num_labels);<br>y = EYE(:, y);<br>delta3 = a3 - y;<br>delta2 = Theta2(:,<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>)' * delta3 .* sigmoidGradient(z2)';<br>Delta1 = delta2 * a1;<br>Delta2 = delta3 * a2;<br><br>Theta1(:,<span class="hljs-number">1</span>)=<span class="hljs-number">0</span>;<br>Theta2(:,<span class="hljs-number">1</span>)=<span class="hljs-number">0</span>;<br>Theta1_grad = Delta1 / m + lambda * Theta1 / m;<br>Theta2_grad = Delta2 / m + lambda * Theta2 / m;<br><br><span class="hljs-comment">% Unroll gradients</span><br>grad = [Theta1_grad(:) ; Theta2_grad(:)];<br><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<h3 id="Training-NN"><a href="#Training-NN" class="headerlink" title="Training NN"></a>Training NN</h3><h4 id="先初始化需要学习的参数"><a href="#先初始化需要学习的参数" class="headerlink" title="先初始化需要学习的参数"></a>先初始化需要学习的参数</h4><p>Initializing Neural Network Parameters</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">W</span> = <span class="hljs-title">randInitializeWeights</span><span class="hljs-params">(L_in, L_out)</span></span><br>W = <span class="hljs-built_in">zeros</span>(L_out, <span class="hljs-number">1</span> + L_in);<br><br>epsilon_init = <span class="hljs-number">0.12</span>;<br>W = <span class="hljs-built_in">rand</span>(L_out,<span class="hljs-number">1</span> + L_in) * <span class="hljs-number">2</span> * epsilon_init - epsilon_init;<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab">initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size);<br>initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels);<br><br><span class="hljs-comment">% Unroll parameters</span><br>initial_nn_params = [initial_Theta1(:) ; initial_Theta2(:)];<br></code></pre></td></tr></table></figure>
<p>这里需要注意初始化的目的是为了防止<code>参数同步</code>。<br>初始化完毕。</p>
<h4 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab">fprintf(<span class="hljs-string">'\nTraining Neural Network... \n'</span>)<br><br>options = optimset(<span class="hljs-string">'MaxIter'</span>, <span class="hljs-number">50</span>);<br><br>lambda = <span class="hljs-number">1</span>;<br><br><span class="hljs-comment">% Create "short hand" for the cost function to be minimized</span><br>costFunction = @(p) nnCostFunction(p, ...<br>                                   input_layer_size, ...<br>                                   hidden_layer_size, ...<br>                                   num_labels, X, y, lambda);<br><br>[nn_params, cost] = fmincg(costFunction, initial_nn_params, options);<br><br><span class="hljs-comment">% Obtain Theta1 and Theta2 back from nn_params</span><br>Theta1 = <span class="hljs-built_in">reshape</span>(nn_params(<span class="hljs-number">1</span>:hidden_layer_size * (input_layer_size + <span class="hljs-number">1</span>)), ...<br>                 hidden_layer_size, (input_layer_size + <span class="hljs-number">1</span>));<br><br>Theta2 = <span class="hljs-built_in">reshape</span>(nn_params((<span class="hljs-number">1</span> + (hidden_layer_size * (input_layer_size + <span class="hljs-number">1</span>))):<span class="hljs-keyword">end</span>), ...<br>                 num_labels, (hidden_layer_size + <span class="hljs-number">1</span>));<br></code></pre></td></tr></table></figure>
<h4 id="Implement-Predict"><a href="#Implement-Predict" class="headerlink" title="Implement Predict"></a>Implement Predict</h4><p>定义PredictFunction</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">p</span> = <span class="hljs-title">predict</span><span class="hljs-params">(Theta1, Theta2, X)</span></span><br><span class="hljs-comment">% Useful values</span><br>m = <span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>);<br>num_labels = <span class="hljs-built_in">size</span>(Theta2, <span class="hljs-number">1</span>);<br><br>p = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(X, <span class="hljs-number">1</span>), <span class="hljs-number">1</span>);<br>h1 = sigmoid([<span class="hljs-built_in">ones</span>(m, <span class="hljs-number">1</span>) X] * Theta1');<br>h2 = sigmoid([<span class="hljs-built_in">ones</span>(m, <span class="hljs-number">1</span>) h1] * Theta2');<br>[dummy, p] = <span class="hljs-built_in">max</span>(h2, [], <span class="hljs-number">2</span>);<br><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>

<figure class="highlight matlab"><table><tr><td class="code"><pre><code class="hljs matlab">pred = predict(Theta1, Theta2, X);<br><br>fprintf(<span class="hljs-string">'\nTraining Set Accuracy: %f\n'</span>, <span class="hljs-built_in">mean</span>(double(pred == y)) * <span class="hljs-number">100</span>);<br></code></pre></td></tr></table></figure>

<h2 id="全篇总结"><a href="#全篇总结" class="headerlink" title="全篇总结"></a>全篇总结</h2><ol>
<li>神经网络算法非常的灵活，激励函数多变，这里仅仅展示了一小部分。但是其中<code>隐层的个数</code>，每个隐层的<code>神经元个数</code>如何确定我仍然不解。</li>
<li>隐层的每个神经元是否有实际的数学意义？</li>
<li>所谓<code>反向传播</code>，其本质是多元微积分的<code>链式法则</code>的应用。</li>
<li>如何判定<code>CostFunction</code>一定有局部最小值？（这一部分的问题或许不在机器学习的范畴之中了吧…）</li>
<li>(疑问很多，不胜枚举)</li>
</ol>
<p>P.S.: 多推倒推倒数学公式还是很有益处的，计划下一篇写一些证明，顺便学习一下怎么在<code>Markdown</code>中插入<code>数学公式</code>!</p>
]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Neural Network</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>TensorFlow</tag>
        <tag>Gradient Descent</tag>
        <tag>MNIST</tag>
        <tag>Neural Network</tag>
        <tag>Backforward</tag>
        <tag>MATLAB</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow学习笔记(2)</title>
    <url>/2019/04/01/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/</url>
    <content><![CDATA[<center>使用**Logistic Regression**实现MNIST手写数字识别</center>

<h2 id="下载MNIST数据集"><a href="#下载MNIST数据集" class="headerlink" title="下载MNIST数据集"></a>下载MNIST数据集</h2><p>TensorFlow提供了一个<code>input_data.py</code>的文件专门用于下载mnist数据。调用方法代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data<br><br>mnist = input_data.read_data_sets(<span class="hljs-string">"MNIST_data"</span>, one_hot=<span class="hljs-literal">True</span>)<br><br>print(mnist.train.images.shape, mnist.train.labels.shape)<br>print(mnist.test.images.shape, mnist.test.labels.shape)<br>print(mnist.validation.images.shape, mnist.validation.labels.shape)<br></code></pre></td></tr></table></figure>

<h2 id="预览一下数据的格式"><a href="#预览一下数据的格式" class="headerlink" title="预览一下数据的格式"></a>预览一下数据的格式</h2><p>trainset是(55000, 784)的，对28*28的图片进行了拉直操作。<br>具体可视化方式如下</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>plt.figure()<br>plt.imshow(mnist.train.images[<span class="hljs-number">0</span>].reshape((<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)))<br>plt.show()<br>print(mnist.train.labels[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>

<h2 id="设定参数"><a href="#设定参数" class="headerlink" title="设定参数"></a>设定参数</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Parameters</span><br>learning_rate = <span class="hljs-number">0.01</span><br>training_epochs = <span class="hljs-number">10</span><br>batch_size = <span class="hljs-number">100</span><br>display_step = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure>

<h2 id="上一篇提到过的placeholder"><a href="#上一篇提到过的placeholder" class="headerlink" title="上一篇提到过的placeholder"></a>上一篇提到过的<strong>placeholder</strong></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># tf Graph Input</span><br>x = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">784</span>])<br>y = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>

<h2 id="需要学习的参数"><a href="#需要学习的参数" class="headerlink" title="需要学习的参数"></a>需要学习的参数</h2><p>这里把All_Theta分开只是为了好计算</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Set model weights</span><br>W = tf.Variable(tf.zeros([<span class="hljs-number">784</span>, <span class="hljs-number">10</span>]), name=<span class="hljs-string">'W'</span>)<br>b = tf.Variable(tf.zeros([<span class="hljs-number">10</span>]), name=<span class="hljs-string">'b'</span>)<br></code></pre></td></tr></table></figure>
<h2 id="建立模型并且使用交叉熵作为CostFunction"><a href="#建立模型并且使用交叉熵作为CostFunction" class="headerlink" title="建立模型并且使用交叉熵作为CostFunction"></a>建立模型并且使用交叉熵作为CostFunction</h2><p>这里使用的是<strong>softmax</strong>函数，比<strong>sigmoid</strong>更好的用于多分类</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Construct model</span><br>pred = tf.nn.softmax(tf.matmul(x, W)+b)<br><span class="hljs-comment"># Minimize error using cross entropy</span><br>cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<h2 id="设置优化器"><a href="#设置优化器" class="headerlink" title="设置优化器"></a>设置优化器</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train_op=tf.train.AdamOptimizer().minimize(cost)<br></code></pre></td></tr></table></figure>
<h3 id="初始化-amp-开始训练"><a href="#初始化-amp-开始训练" class="headerlink" title="初始化&amp;开始训练"></a>初始化&amp;开始训练</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">init = tf.global_variables_initializer()<br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    sess.run(init)<br><br>    <span class="hljs-comment"># Training cycle</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(training_epochs):<br>        avg_cost = <span class="hljs-number">0.</span><br>        total_batch = int(mnist.train.num_examples / batch_size)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(total_batch):<br>            batch_xs, batch_ys = mnist.train.next_batch(batch_size)<br>            _,c=sess.run([train_op,cost],feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)<br>            <span class="hljs-comment"># Compute average loss</span><br>            avg_cost += c / total_batch<br><br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % display_step == <span class="hljs-number">0</span>:<br>            print(<span class="hljs-string">"Epoch:"</span>, <span class="hljs-string">'%04d'</span> % (epoch + <span class="hljs-number">1</span>), <span class="hljs-string">"cost="</span>, <span class="hljs-string">"&#123;:.9f&#125;"</span>.format(avg_cost))<br><br>    <span class="hljs-comment"># test</span><br>    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,<span class="hljs-number">1</span>),tf.argmax(y,<span class="hljs-number">1</span>)),tf.float32))<br>    print(<span class="hljs-string">'test accuracy'</span>,acc.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))<br></code></pre></td></tr></table></figure>
<h2 id="完整代码如下"><a href="#完整代码如下" class="headerlink" title="完整代码如下"></a>完整代码如下</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data<br>mnist = input_data.read_data_sets(<span class="hljs-string">"MNIST_data"</span>, one_hot=<span class="hljs-literal">True</span>)<br><br>print(mnist.train.images.shape, mnist.train.labels.shape)<br>print(mnist.test.images.shape, mnist.test.labels.shape)<br>print(mnist.validation.images.shape, mnist.validation.labels.shape)<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>plt.figure()<br>plt.imshow(mnist.train.images[<span class="hljs-number">0</span>].reshape((<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)))<br>plt.show()<br>print(mnist.train.labels[<span class="hljs-number">0</span>])<br><br><span class="hljs-comment"># Parameters</span><br>learning_rate = <span class="hljs-number">0.01</span><br>training_epochs = <span class="hljs-number">10</span><br>batch_size = <span class="hljs-number">100</span><br>display_step = <span class="hljs-number">1</span><br><br><span class="hljs-comment"># tf Graph Input</span><br>x = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">784</span>])<br>y = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">10</span>])<br><br><span class="hljs-comment"># Set model weights</span><br>W = tf.Variable(tf.zeros([<span class="hljs-number">784</span>, <span class="hljs-number">10</span>]), name=<span class="hljs-string">'W'</span>)<br>b = tf.Variable(tf.zeros([<span class="hljs-number">10</span>]), name=<span class="hljs-string">'b'</span>)<br><br><span class="hljs-comment"># Construct model</span><br>pred = tf.nn.softmax(tf.matmul(x, W)+b)<br><span class="hljs-comment"># Minimize error using cross entropy</span><br>cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=<span class="hljs-number">1</span>))<br><br>train_op=tf.train.AdamOptimizer().minimize(cost)<br>init = tf.global_variables_initializer()<br><br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    sess.run(init)<br><br>    <span class="hljs-comment"># Training cycle</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(training_epochs):<br>        avg_cost = <span class="hljs-number">0.</span><br>        total_batch = int(mnist.train.num_examples / batch_size)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(total_batch):<br>            batch_xs, batch_ys = mnist.train.next_batch(batch_size)<br>            _,c=sess.run([train_op,cost],feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)<br>            <span class="hljs-comment"># Compute average loss</span><br>            avg_cost += c / total_batch<br><br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % display_step == <span class="hljs-number">0</span>:<br>            print(<span class="hljs-string">"Epoch:"</span>, <span class="hljs-string">'%04d'</span> % (epoch + <span class="hljs-number">1</span>), <span class="hljs-string">"cost="</span>, <span class="hljs-string">"&#123;:.9f&#125;"</span>.format(avg_cost))<br><br>    <span class="hljs-comment"># test</span><br>    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,<span class="hljs-number">1</span>),tf.argmax(y,<span class="hljs-number">1</span>)),tf.float32))<br>    print(<span class="hljs-string">'test accuracy'</span>,acc.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))<br></code></pre></td></tr></table></figure>
<p>运行结果:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0001</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.633361989</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0002</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.352441514</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0003</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.314567825</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0004</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.295945743</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0005</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.285345373</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0006</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.277918718</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0007</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.272353557</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0008</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.267977367</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0009</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.264319934</span><br><span class="hljs-attr">Epoch:</span> <span class="hljs-number">0010</span> <span class="hljs-string">cost=</span> <span class="hljs-number">0.261488377</span><br><span class="hljs-string">test</span> <span class="hljs-string">accuracy</span> <span class="hljs-number">0.9271</span><br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>TensorFlow</tag>
        <tag>Gradient Descent</tag>
        <tag>Logistic Regression</tag>
        <tag>MNIST</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow学习笔记</title>
    <url>/2019/03/28/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>最近在Coursera上学的 <strong>Machine Learning</strong>正好讲到<strong>Neural Network</strong></p>
<h2 id="使用TensorFlow-学习神经网络"><a href="#使用TensorFlow-学习神经网络" class="headerlink" title="使用TensorFlow 学习神经网络"></a>使用TensorFlow 学习神经网络</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>使用<strong>张量Tensor</strong>和<strong>算子Operator</strong>构建<strong>流Flow</strong><br>然后使用<strong>会话Session</strong>计算<br>意思就是说，主要分两步进行。第一步是构建Flow，第二步是执行Flow。<br>很简单，开干。</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><h4 id="初始化权重矩阵"><a href="#初始化权重矩阵" class="headerlink" title="初始化权重矩阵"></a>初始化权重矩阵</h4><p>这里初始化了(2,3)和(3,1)的两个矩阵，其中里面的元素全部随机服从标准差为1，mean=0的正态分布。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">w1 = tf.Variable(tf.random_normal((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>), stddev=<span class="hljs-number">1</span>, seed=<span class="hljs-number">1</span>))<br>w2 = tf.Variable(tf.random_normal((<span class="hljs-number">3</span>,<span class="hljs-number">1</span>), stddev=<span class="hljs-number">1</span>, seed=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<h4 id="构建Flow"><a href="#构建Flow" class="headerlink" title="构建Flow"></a>构建Flow</h4><p>很简单的前向传播模型，看代码就懂。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">x = tf.constant([[<span class="hljs-number">0.7</span>, <span class="hljs-number">0.9</span>]])<br>a = tf.matmul(x, w1)<br>y = tf.matmul(a, w2)<br></code></pre></td></tr></table></figure>
<h4 id="创建Session"><a href="#创建Session" class="headerlink" title="创建Session"></a>创建Session</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">sess = tf.Session()<br>sess.run(w1.initializer)<br>sess.run(w2.initializer)<br>print(sess.run(y))<br>sess.close()<br></code></pre></td></tr></table></figure>
<p>记得关闭Session，释放资源。</p>
<h4 id="全局初始化"><a href="#全局初始化" class="headerlink" title="全局初始化"></a>全局初始化</h4><p>在Flow比较复杂的时候，神经元依赖关系复杂，使用全局初始化函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">init_op = tf.global_variables_initializer()<br>sess.run(init_op)<br></code></pre></td></tr></table></figure>
<p>这个函数可以自动处理变量之间依赖关系。</p>
<a id="more"></a>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><p>使用TensorBoard进行数据可视化</p>
<h4 id="生成日志"><a href="#生成日志" class="headerlink" title="生成日志"></a>生成日志</h4><p>生成一个写日志的 writer，并将当前的 TensorFlow 计算图写入日志。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">writer = tf.summary.FileWriter(<span class="hljs-string">"log"</span>, tf.get_default_graph())<br>writer.close()<br></code></pre></td></tr></table></figure>
<p>然后在terminal里输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">tensorboard --logdir=~/Desktop/tf/<span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure>
<p>就可以看到可视化的Flow了</p>
<h3 id="张量Tensor"><a href="#张量Tensor" class="headerlink" title="张量Tensor"></a>张量Tensor</h3><p>在TensorFlow中，变量的声明函数<strong>tf.Variable</strong>是一个运算。<br>这个运算的输出结果是一个张量。</p>
<p>在构建机器学习模型时，我们需要区分需要被学习的<strong>参数</strong>和无法被学习的<strong>超参数</strong>。所以若声明变量时参数<strong>tainable</strong>为<strong>True</strong>，那么这个变量将会被加入到<strong>GraphKeys.TRAINABLE_VARIABLES</strong>集合中。<br>可以通过<strong>tf.trainable_variables</strong>函数得到所有需要优化的参数。</p>
<h3 id="类型Type"><a href="#类型Type" class="headerlink" title="类型Type"></a>类型Type</h3><p><strong>int</strong>, <strong>float32</strong>这种，声明时啥样就啥样。</p>
<h3 id="维度Shape"><a href="#维度Shape" class="headerlink" title="维度Shape"></a>维度Shape</h3><p>维度在运算中是可以被改变的，但是需要加入<strong>validate_shape=False</strong>参数。</p>
<h2 id="训练神经网络模型"><a href="#训练神经网络模型" class="headerlink" title="训练神经网络模型"></a>训练神经网络模型</h2><p>最常用的算法是<strong>反向传播算法backpropagation</strong><br>大体思路就是：<br>    1. 选取一部分训练数据batch<br>    2. 通过前向传播获得预测值<br>    3. 通过反向传播更新变量<br>上面这三步，就是一个迭代<strong>iteration</strong></p>
<h3 id="TensorFlow对数据的读取"><a href="#TensorFlow对数据的读取" class="headerlink" title="TensorFlow对数据的读取"></a>TensorFlow对数据的读取</h3><p>TensorFlow提供了<strong>placeholder</strong>机制用于提供输入数据，将数据通过 placeholder传入Flow即可。</p>
<h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> numpy . random <span class="hljs-keyword">import</span> RandomState<br><br>batch_size = <span class="hljs-number">8</span><br><br>w1 = tf.Variable(tf.random_normal([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], stddev=<span class="hljs-number">1</span>, seed=<span class="hljs-number">1</span>))<br>w2 = tf.Variable(tf.random_normal([<span class="hljs-number">3</span>, <span class="hljs-number">1</span>], stddev=<span class="hljs-number">1</span>, seed=<span class="hljs-number">1</span>))<br><br>x = tf.placeholder(tf.float32, shape=(<span class="hljs-literal">None</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'x-input'</span>)<br>y_ = tf.placeholder(tf.float32, shape=(<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>), name=<span class="hljs-string">'y-input'</span>)<br><br>a = tf.matmul(x, w1)<br>y = tf.matmul(a, w2)<br><br>y = tf.sigmoid(y)<br>cross_entropy = -tf.reduce_mean(<br>    y_ * tf.log(tf.clip_by_value(y, <span class="hljs-number">1e-10</span>, <span class="hljs-number">1.0</span>))<br>    +(<span class="hljs-number">1</span>-y)*tf.log(tf.clip_by_value(<span class="hljs-number">1</span>-y, <span class="hljs-number">1e-10</span>, <span class="hljs-number">1.0</span>)))<br>learning_rate = <span class="hljs-number">0.001</span><br>train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)<br><br>rdm = RandomState(<span class="hljs-number">1</span>)<br>dataset_size = <span class="hljs-number">128</span><br>X = rdm.rand(dataset_size, <span class="hljs-number">2</span>)<br><br>Y = [[int(x1+x2 &lt; <span class="hljs-number">1</span>)] <span class="hljs-keyword">for</span> (x1, x2) <span class="hljs-keyword">in</span> X]<br><br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    init_op = tf.global_variables_initializer()<br>    sess.run(init_op)<br>    print(sess.run(w1))<br>    print(sess.run(w2))<br>    <br>    STEPS = <span class="hljs-number">5000</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(STEPS):<br>        start = (i * batch_size) % dataset_size<br>        end = min(start+batch_size, dataset_size)<br>        sess .run(train_step,feed_dict=&#123;x: X[start:end], y_: Y[start:end]&#125;)<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:<br>            total_cross_entropy = sess.run(cross_entropy, feed_dict=&#123;x: X, y_: Y&#125;)<br>            print(<span class="hljs-string">"After %d training step (s) , cross entropy on all data is %g"</span> %(i , total_cross_entropy))<br>    <br>    print(sess.run(w1))<br>    print(sess.run(w2))<br></code></pre></td></tr></table></figure>
<p>运行结果如下</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><code class="hljs angelscript">[[<span class="hljs-number">-0.8113182</span>   <span class="hljs-number">1.4845988</span>   <span class="hljs-number">0.06532937</span>]<br> [<span class="hljs-number">-2.4427042</span>   <span class="hljs-number">0.0992484</span>   <span class="hljs-number">0.5912243</span> ]]<br>[[<span class="hljs-number">-0.8113182</span> ]<br> [ <span class="hljs-number">1.4845988</span> ]<br> [ <span class="hljs-number">0.06532937</span>]]<br>After <span class="hljs-number">0</span> training step (s) , cross entropy on all data <span class="hljs-keyword">is</span> <span class="hljs-number">0.559635</span><br>After <span class="hljs-number">1000</span> training step (s) , cross entropy on all data <span class="hljs-keyword">is</span> <span class="hljs-number">0.554203</span><br>After <span class="hljs-number">2000</span> training step (s) , cross entropy on all data <span class="hljs-keyword">is</span> <span class="hljs-number">0.553355</span><br>After <span class="hljs-number">3000</span> training step (s) , cross entropy on all data <span class="hljs-keyword">is</span> <span class="hljs-number">0.553042</span><br>After <span class="hljs-number">4000</span> training step (s) , cross entropy on all data <span class="hljs-keyword">is</span> <span class="hljs-number">0.552882</span><br>[[<span class="hljs-number">-2.5097506</span>  <span class="hljs-number">3.0530994</span>  <span class="hljs-number">2.779182</span> ]<br> [<span class="hljs-number">-4.0340977</span>  <span class="hljs-number">1.5597332</span>  <span class="hljs-number">3.26844</span>  ]]<br>[[<span class="hljs-number">-2.2767503</span>]<br> [ <span class="hljs-number">3.2578714</span>]<br> [ <span class="hljs-number">2.3726451</span>]]<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Neural Network</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫抓取证券时报内容</title>
    <url>/2019/03/24/%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96%E8%AF%81%E5%88%B8%E6%97%B6%E6%8A%A5%E5%86%85%E5%AE%B9/</url>
    <content><![CDATA[<p>本次目标是抓取<a href="http://epaper.stcn.com" target="_blank" rel="noopener">证券时报电子报</a>往期内容并整理分类，为后面的数据分析做准备。</p>
<h3 id="准备工具"><a href="#准备工具" class="headerlink" title="准备工具"></a>准备工具</h3><p>Safari Develop mode, Python, Jupyter Notebook</p>
<h3 id="代码如下"><a href="#代码如下" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Init</span><br><span class="hljs-keyword">import</span> urllib.parse<br><span class="hljs-keyword">import</span> urllib.request<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">import</span> time<br><br>year = <span class="hljs-number">2019</span><br>month = <span class="hljs-number">3</span><br>day = <span class="hljs-number">23</span><br><br>user_agent = <span class="hljs-string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span><br>headers = &#123; <span class="hljs-string">'User-Agent'</span> : user_agent &#125;<br>data = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Generate DateString</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">DateStr</span><span class="hljs-params">(year, month, day)</span>:</span><br>    Date = str(year) + <span class="hljs-string">'-'</span><br>    <span class="hljs-keyword">if</span> month &lt; <span class="hljs-number">10</span>:<br>        Date = Date + <span class="hljs-string">'0'</span> + str(month)<br>    <span class="hljs-keyword">else</span>:<br>        Date = Date + str(month)<br>    Date = Date + <span class="hljs-string">'/'</span><br>    <span class="hljs-keyword">if</span> day &lt; <span class="hljs-number">10</span>:<br>        Date = Date + <span class="hljs-string">'0'</span> + str(day)<br>    <span class="hljs-keyword">else</span>:<br>        Date = Date + str(day)<br>    <span class="hljs-keyword">return</span> Date<br></code></pre></td></tr></table></figure>

<pre><code>2019-03/24</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Generate yyyy-mm-dd URL</span><br><span class="hljs-comment"># URL = GenURL(Date)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GenURL</span><span class="hljs-params">(Date)</span>:</span><br>    url = <span class="hljs-string">'http://epaper.stcn.com/paper/zqsb/html/'</span>+ Date + <span class="hljs-string">'/node_2.htm'</span><br>    <span class="hljs-keyword">return</span> url<br></code></pre></td></tr></table></figure>

<pre><code>http://epaper.stcn.com/paper/zqsb/html/2019-03/24/node_2.htm</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># content = GetContent(URL)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GetContent</span><span class="hljs-params">(url)</span>:</span><br>    req = urllib.request.Request(url, data, headers)<br>    response = urllib.request.urlopen(req)<br>    content = response.read().decode(<span class="hljs-string">'utf-8'</span>)<br>    <span class="hljs-keyword">return</span> content<br></code></pre></td></tr></table></figure>

<pre><code>&lt;script&gt;
window.location=&quot;/paper/zqsb/html/epaper/index/index.htm&quot;;
&lt;/script&gt;

http://epaper.stcn.com/paper/zqsb/html/2019-03/24/node_2.htm</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Analysis the paper</span><br><span class="hljs-comment"># PaperContent = GetPaper(content)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GetPaper</span><span class="hljs-params">(content)</span>:</span><br>    _soup = BeautifulSoup(content, <span class="hljs-string">"html.parser"</span>)<br>    founder_content = _soup.find(<span class="hljs-string">"founder-content"</span>)<br>    Paper = <span class="hljs-string">''</span><br>    <span class="hljs-keyword">for</span> paper <span class="hljs-keyword">in</span> founder_content.find_all(<span class="hljs-string">"p"</span>):<br>        <span class="hljs-keyword">if</span> paper.string != <span class="hljs-literal">None</span>:<br>            Paper = Paper + paper.string<br>    <span class="hljs-keyword">return</span> Paper<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Get Paper Link List</span><br><span class="hljs-comment"># URL = GenURL(year, month, day)</span><br><span class="hljs-comment"># content = GetContent(URL)</span><br><span class="hljs-comment"># LinkList = GetLink(URL, content)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GetLink</span><span class="hljs-params">(url, content)</span>:</span><br>    LinkList = []<br>    soup = BeautifulSoup(content, <span class="hljs-string">"html.parser"</span>)<br>    url = url[:<span class="hljs-number">50</span>]<br>    <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> soup.find_all(<span class="hljs-string">"a"</span>,href=re.compile(<span class="hljs-string">"^content"</span>)):<br>        PaperURL = url + link.get(<span class="hljs-string">'href'</span>)<br>        LinkList.append(PaperURL)<br>    <span class="hljs-keyword">return</span> LinkList<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Work</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GetAllArticles</span><span class="hljs-params">(year, month, day)</span>:</span><br>    Date = DateStr(year, month, day)<br>    URL = GenURL(Date) <span class="hljs-comment"># Generate yyyy-mm-dd Home Page</span><br>    HomePageContent = GetContent(URL) <span class="hljs-comment"># Get the Content of the Home Page</span><br>    LinkList = GetLink(URL, HomePageContent) <span class="hljs-comment"># Get the PaperLink from the Home Page</span><br>    <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> LinkList:<br>        PaperContent = GetContent(link) <span class="hljs-comment"># Get the PaperContent from the link</span><br>        PaperText = GetPaper(PaperContent) <span class="hljs-comment"># Convert PaperContent to PaperText</span><br>        Date = Date.replace(<span class="hljs-string">'/'</span>,<span class="hljs-string">'-'</span>)<br>        FileName = Date + <span class="hljs-string">'.txt'</span><br>        f = open(FileName, <span class="hljs-string">'a+'</span>)<br>        f.write(<span class="hljs-string">"Time : %s\n"</span> % time.ctime())<br>        f.write(PaperText)<br>        f.write(<span class="hljs-string">'\n'</span>)<br>        f.close()<br>        time.sleep(<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">GetAllArticles(year, month, day)<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Web Spider</tag>
        <tag>Html</tag>
      </tags>
  </entry>
  <entry>
    <title>macOS下Spark的安装</title>
    <url>/2019/03/22/mac%E4%B8%8BSpark%E7%9A%84%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>最近参与了一个研究经济政策不确定性对股市波动影响的项目，里面对于新闻文本需要用到NLP，而且是海量文本。正好最近在投各大厂的简历，数据分析相关的岗位都要求熟悉Spark，时间有点紧，火烧眉毛了，那就来学一学。</p>
<p><strong>就不介绍啥是Spark了，直接上干货</strong></p>
<a id="more"></a>
<h2 id="Spark的安装"><a href="#Spark的安装" class="headerlink" title="Spark的安装"></a>Spark的安装</h2><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>macOS有一点非常的好，它拥有一个无比强大的Terminal，什么事一行命令就可以搞定。</p>
<h4 id="神器Homebrew"><a href="#神器Homebrew" class="headerlink" title="神器Homebrew"></a>神器Homebrew</h4><p><a href="https://brew.sh" target="_blank" rel="noopener">Homebrew</a>是mac下的头牌神器了，要装什么一行”brew install”就可以搞定。把它当作Ubuntu下的”apt install”就好了。<br><a href="https://brew.sh" target="_blank" rel="noopener">Homebrew</a></p>
<h4 id="安装Java-JDK-1-8-并配置好环境变量"><a href="#安装Java-JDK-1-8-并配置好环境变量" class="headerlink" title="安装Java JDK 1.8, 并配置好环境变量"></a>安装Java JDK 1.8, 并配置好环境变量</h4><p>下载地址：<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">JDK8</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">~ vim .zshrc<br></code></pre></td></tr></table></figure>
<p> 在行末加上<br> <figure class="highlight zsh"><table><tr><td class="code"><pre><code class="hljs zsh"><span class="hljs-built_in">export</span> JAVA_HOME=<span class="hljs-string">"/Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home"</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$PATH</span>"</span><br></code></pre></td></tr></table></figure><br><code>:wq</code>后<code>source ~/.zsh</code><br>在Terminal中输入<code>java -version</code>查看安装结果</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">java version <span class="hljs-string">"1.8.0_201"</span><br>Java(TM) SE Runtime Environment (build 1.8.0_201-b09)<br>Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)<br></code></pre></td></tr></table></figure>
<h4 id="安装Scala"><a href="#安装Scala" class="headerlink" title="安装Scala"></a>安装Scala</h4><p>使用<code>brew install scala</code>安装Scala</p>
<h3 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h3><p>使用<code>brew install apache-spark</code>安装Spark<br>配置Spark</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Spark的配置</span><br><br><span class="hljs-built_in">export</span> SPARK_PATH=<span class="hljs-string">"/usr/local/Cellar/apache-spark/2.4.0"</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$SPARK_PATH</span>/bin:<span class="hljs-variable">$PATH</span>"</span><br></code></pre></td></tr></table></figure>

<h2 id="运行Spark"><a href="#运行Spark" class="headerlink" title="运行Spark"></a>运行Spark</h2><p>在Terminal中输入<code>spark-shell</code>将得到如下信息<br><img src="/2019/03/22/mac%E4%B8%8BSpark%E7%9A%84%E5%AE%89%E8%A3%85/1.png" alt="SparkInfo"></p>
<h2 id="练练手"><a href="#练练手" class="headerlink" title="练练手"></a>练练手</h2><h3 id="使用spark-shell完成单词统计功能"><a href="#使用spark-shell完成单词统计功能" class="headerlink" title="使用spark-shell完成单词统计功能"></a>使用spark-shell完成单词统计功能</h3><p>先随便找一篇文章<br><img src="/2019/03/22/mac%E4%B8%8BSpark%E7%9A%84%E5%AE%89%E8%A3%85/2.png" alt="text"><br>保存在<code>/Users/xxx/Desktop/Chapter_1.txt</code><br>输入命令<code>spark-shell</code>进入scala编写环境<br>建立一个RDD</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> textFile = sc.textFile(<span class="hljs-string">"file:///Users/xxx/Desktop/Chapter_1.txt"</span>)<br>textFile: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[<span class="hljs-type">String</span>] = file:<span class="hljs-comment">///Users/xxx/Desktop/Chapter_1.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24</span><br></code></pre></td></tr></table></figure>
<p>代码中通过<code>file://</code>前缀指定读取本地文件</p>
<h4 id="count-操作"><a href="#count-操作" class="headerlink" title="count()操作"></a>count()操作</h4><figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; textFile.count()     <span class="hljs-comment">// RDD 中的 item 数量，对于文本文件，就是总行数</span><br>res0: <span class="hljs-type">Long</span> = <span class="hljs-number">183</span><br></code></pre></td></tr></table></figure>
<h4 id="first-操作"><a href="#first-操作" class="headerlink" title="first()操作"></a>first()操作</h4><figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; textFile.first()     <span class="hljs-comment">// RDD 中的第一个 item，对于文本文件，就是第一行内容</span><br>res1: <span class="hljs-type">String</span> = <span class="hljs-type">Then</span> wear the gold hat, <span class="hljs-keyword">if</span> that will move her;<br></code></pre></td></tr></table></figure>
<h4 id="通过-filter-transformation-来返回一个新的-RDD"><a href="#通过-filter-transformation-来返回一个新的-RDD" class="headerlink" title="通过 filter transformation 来返回一个新的 RDD"></a>通过 filter transformation 来返回一个新的 RDD</h4><figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> linesWithGatsby = textFile.filter(line =&gt; line.contains(<span class="hljs-string">"Gatsby"</span>))   <span class="hljs-comment">// 筛选出包含 Gatsby 的行</span><br>linesWithGatsby: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[<span class="hljs-type">String</span>] = <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">5</span>] at filter at &lt;console&gt;:<span class="hljs-number">25</span><br><br>scala&gt; linesWithGatsby.count()     <span class="hljs-comment">// 统计行数</span><br>res2: <span class="hljs-type">Long</span> = <span class="hljs-number">8</span><br></code></pre></td></tr></table></figure>
<p>寻找包含单词最多的那一行内容共有几个单词</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; textFile.map(line =&gt; line.split(<span class="hljs-string">" "</span>).size).reduce((a, b) =&gt; <span class="hljs-keyword">if</span> (a &gt; b) a <span class="hljs-keyword">else</span> b)<br>res3: <span class="hljs-type">Int</span> = <span class="hljs-number">203</span><br></code></pre></td></tr></table></figure>
<p>代码首先将每一行内容 map 为一个整数，这将创建一个新的 RDD，并在这个 RDD 中执行 reduce 操作，找到最大的数。map()、reduce() 中的参数是 Scala 的函数字面量（function literals，也称为闭包 closures），并且可以使用语言特征或 Scala/Java 的库。例如，通过使用 Math.max() 函数（需要导入 Java 的 Math 库），可以使上述代码更容易理解:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">import</span> java.lang.<span class="hljs-type">Math</span> <span class="hljs-comment">//先导入Math函数</span><br><span class="hljs-keyword">import</span> java.lang.<span class="hljs-type">Math</span><br><br>scala&gt; textFile.map(line =&gt; line.split(<span class="hljs-string">" "</span>).size).reduce((a, b) =&gt; <span class="hljs-type">Math</span>.max(a, b))<br>res4: <span class="hljs-type">Int</span> = <span class="hljs-number">203</span><br></code></pre></td></tr></table></figure>
<p>Hadoop MapReduce 是常见的数据流模式，在 Spark 中同样可以实现（下面这个例子也就是 WordCount）:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> wordCounts = textFile.flatMap(line =&gt; line.split(<span class="hljs-string">" "</span>)).map(word =&gt; (word, <span class="hljs-number">1</span>)).reduceByKey((a, b) =&gt; a + b)   <span class="hljs-comment">// 实现单词统计</span><br>wordCounts: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[(<span class="hljs-type">String</span>, <span class="hljs-type">Int</span>)] = <span class="hljs-type">ShuffledRDD</span>[<span class="hljs-number">10</span>] at reduceByKey at &lt;console&gt;:<span class="hljs-number">26</span><br><br>scala&gt; wordCounts.collect()    <span class="hljs-comment">// 输出单词统计结果</span><br>res5: <span class="hljs-type">Array</span>[(<span class="hljs-type">String</span>, <span class="hljs-type">Int</span>)] = <span class="hljs-type">Array</span>((paper,<span class="hljs-number">1</span>), (consoling,<span class="hljs-number">1</span>), (opening,<span class="hljs-number">1</span>), (month,,<span class="hljs-number">1</span>), (tone.,<span class="hljs-number">1</span>), (pleasant,<span class="hljs-number">2</span>), (national,<span class="hljs-number">1</span>), (wasn<span class="hljs-symbol">'t</span>,<span class="hljs-number">3</span>), (been,<span class="hljs-number">14</span>), (advice,<span class="hljs-number">1</span>), (reserve,<span class="hljs-number">1</span>), (you!<span class="hljs-string">",1), (breath,1), ("</span><span class="hljs-type">Whenever</span>,<span class="hljs-number">1</span>), (war.<span class="hljs-string">",1), (specimen,1), (knows,1), (substitute,1), (husky,1), (wind.,1), (afterward,1), (garages,,1), (instinct,1), (are,9), (revelations,1), (Western,1), (politician,,1), (shut,1), (alert,1), (porch.,2), (telephone,,1), (murmuring,1), (hear.,1), (we're,2), (away,3), (Nordics.,1), ("</span><span class="hljs-type">Don</span><span class="hljs-symbol">'t</span>,<span class="hljs-number">3</span>), (minute,<span class="hljs-number">3</span>), (high-bouncing,<span class="hljs-number">1</span>), (<span class="hljs-string">"Wake,1), (car,1), (dust,1), (going,6), (neighbor's,2), (a--of,1), (complacency,,1), (tangible,1), (Nick?,1), (them,7), (infinite,1), ("</span><span class="hljs-type">Sophisticated</span>--<span class="hljs-type">God</span>,,<span class="hljs-number">1</span>), (recently,<span class="hljs-number">1</span>), (to?<span class="hljs-string">",1), (Tom,"</span>,<span class="hljs-number">1</span>), (lived,<span class="hljs-number">1</span>), (air.,<span class="hljs-number">2</span>), (blew,<span class="hljs-number">3</span>), (again.,<span class="hljs-number">4</span>), (promises,<span class="hljs-number">1</span>), (ecstat...<br></code></pre></td></tr></table></figure>
<p>上述便是一些简单的单词统计的应用。</p>
<h4 id="退出"><a href="#退出" class="headerlink" title="退出"></a>退出</h4><p>输入<code>:quit</code>即可退出</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总体来说，mac安装Spark还是很愉快的，还有许多尚未了解的东西，一点一点的啃掉吧！</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>学习过程中参照了这位<a href="http://codingxiaxw.cn/2016/12/07/60-mac-spark/" target="_blank" rel="noopener">大佬的blog</a>安装过程有稍许不同。</p>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>scala</tag>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title>Arch Linux 安装笔记</title>
    <url>/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>以前需要Linux环境时，mac上能干直接mac，mac不行就Ubuntu。久闻ArchLinux大名，今天就学习一下。</p>
<h3 id="下载iso镜像"><a href="#下载iso镜像" class="headerlink" title="下载iso镜像"></a>下载iso镜像</h3><p>在宿舍是教育网，    <a href="http://mirrors.nju.edu.cn" target="_blank" rel="noopener">南大镜像站</a>、<a href="https://mirrors.tuna.tsinghua.edu.cn" target="_blank" rel="noopener">清华镜像站</a>都很快。这里我在清华镜像站下的最新版archlinux。<br>以后会专门写一篇介绍各大镜像站的使用方法。</p>
<h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><!-- ![你想输入的替代文字](/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/1.png) -->
<p>不像Ubuntu，Parallels没有Arch Linux选项，这里我选择了<strong>Other Linux 3.x kernel 64-bit</strong>，默认的配置应该足够了。</p>
<a id="more"></a>
<h4 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h4><p>选择第一项<img src="/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/1.png" alt="step1"></p>
<h5 id="开始分区"><a href="#开始分区" class="headerlink" title="开始分区"></a>开始分区</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># fdisk /dev/sda</span><br></code></pre></td></tr></table></figure>
<h5 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Command (m for help): n</span><br><span class="hljs-comment"># Partition type: Select (default p):</span><br><span class="hljs-comment"># Partition number (1-4, default 1):</span><br><span class="hljs-comment"># First sector (2048-209715199, default 2048):</span><br><span class="hljs-comment"># Last sector, +sectors or +size&#123;K,M,G&#125; (2048-209715199....., default 209715199): +15G</span><br></code></pre></td></tr></table></figure>

<p>建立第二个分区:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Command (m for help): n</span><br><span class="hljs-comment"># Partition type: Select (default p):</span><br><span class="hljs-comment"># Partition number (1-4, default 2):</span><br><span class="hljs-comment"># First sector (31459328-209715199, default 31459328):</span><br><span class="hljs-comment"># Last sector, +sectors or +size&#123;K,M,G&#125; (31459328-209715199....., default 209715199):</span><br></code></pre></td></tr></table></figure>
<p>现在预览下分区表:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Command (m for help): p</span><br></code></pre></td></tr></table></figure>
<p>向磁盘写入这些改动:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Command (m for help): w</span><br></code></pre></td></tr></table></figure>
<p>程序将显示如下信息:</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><code class="hljs pgsql">The <span class="hljs-keyword">partition</span> <span class="hljs-keyword">table</span> has been altered!<br>Calling ioctl() <span class="hljs-keyword">to</span> re-<span class="hljs-keyword">read</span> <span class="hljs-keyword">partition</span> <span class="hljs-keyword">table</span>.<br>Syncing disks.<br></code></pre></td></tr></table></figure>
<h4 id="安装基本系统"><a href="#安装基本系统" class="headerlink" title="安装基本系统"></a>安装基本系统</h4><p>这一步需要联网</p>
<h5 id="检测网络状态"><a href="#检测网络状态" class="headerlink" title="检测网络状态"></a>检测网络状态</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ping baidu.com</span><br></code></pre></td></tr></table></figure>

<h5 id="用nano命令将清华源加在最前面"><a href="#用nano命令将清华源加在最前面" class="headerlink" title="用nano命令将清华源加在最前面"></a>用nano命令将清华源加在最前面</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># nano /etc/pacman.d/mirrorlist</span><br></code></pre></td></tr></table></figure>
<p><img src="/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/2.png" alt="mirrors"></p>
<h5 id="刷新列表-安装基本系统"><a href="#刷新列表-安装基本系统" class="headerlink" title="刷新列表, 安装基本系统"></a>刷新列表, 安装基本系统</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># pacman -Syy</span><br><span class="hljs-comment"># pacstrap -i /mnt base</span><br><br>Enter a selection (default-all):<br>Enter a number (default=1):<br>:: Proceed with installation? [Y/n] Y<br></code></pre></td></tr></table></figure>
<h5 id="生成fstab分区表"><a href="#生成fstab分区表" class="headerlink" title="生成fstab分区表"></a>生成fstab分区表</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># genfstab -U -p /mnt &gt;&gt; /mnt/etc/fstab</span><br></code></pre></td></tr></table></figure>
<h5 id="chroot-到新系统开始配置"><a href="#chroot-到新系统开始配置" class="headerlink" title="chroot 到新系统开始配置"></a>chroot 到新系统开始配置</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># arch-chroot /mnt /bin/bash</span><br></code></pre></td></tr></table></figure>

<h5 id="系统本地化，设置本地语言，地点等信息"><a href="#系统本地化，设置本地语言，地点等信息" class="headerlink" title="系统本地化，设置本地语言，地点等信息"></a>系统本地化，设置本地语言，地点等信息</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># nano /etc/locale.gen</span><br>en_US.UTF-8 UTF-8<br>zh_CN.UTF-8 UTF-8<br>zh_TW.UTF-8 UTF-8<br></code></pre></td></tr></table></figure>
<h6 id="接着执行locale-gen以生成locale讯息"><a href="#接着执行locale-gen以生成locale讯息" class="headerlink" title="接着执行locale-gen以生成locale讯息"></a>接着执行locale-gen以生成locale讯息</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># locale-gen</span><br></code></pre></td></tr></table></figure>

<h6 id="创建-locale-conf-并提交本地化选项"><a href="#创建-locale-conf-并提交本地化选项" class="headerlink" title="创建 locale.conf 并提交本地化选项"></a>创建 locale.conf 并提交本地化选项</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># echo LANG=en_US.UTF-8 &gt; /etc/locale.conf</span><br></code></pre></td></tr></table></figure>

<h6 id="设置时区"><a href="#设置时区" class="headerlink" title="设置时区"></a>设置时区</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></code></pre></td></tr></table></figure>

<h6 id="设置时间"><a href="#设置时间" class="headerlink" title="设置时间"></a>设置时间</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># hwclock --systohc --utc</span><br></code></pre></td></tr></table></figure>

<h6 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># echo 主机名 &gt; /etc/hostname</span><br><span class="hljs-comment"># nano /etc/hosts</span><br><span class="hljs-comment">#&lt;ip-address&gt; &lt;hostname.domain.org&gt; &lt;hostname&gt;</span><br>127.0.0.1    localhost.localdomain  localhost 主机名  <br>::1          localhost.localdomain  localhost<br></code></pre></td></tr></table></figure>

<h6 id="设置root密码"><a href="#设置root密码" class="headerlink" title="设置root密码"></a>设置root密码</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># passwd</span><br></code></pre></td></tr></table></figure>

<h6 id="安装启动引导器grub"><a href="#安装启动引导器grub" class="headerlink" title="安装启动引导器grub"></a>安装启动引导器grub</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># pacman -S grub</span><br><span class="hljs-comment"># grub-install --target=i386-pc --recheck /dev/sda</span><br><span class="hljs-comment"># grub-mkconfig -o /boot/grub/grub.cfg</span><br></code></pre></td></tr></table></figure>

<h6 id="离开-chroot-环境"><a href="#离开-chroot-环境" class="headerlink" title="离开 chroot 环境"></a>离开 chroot 环境</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># exit</span><br></code></pre></td></tr></table></figure>

<h6 id="重启计算机"><a href="#重启计算机" class="headerlink" title="重启计算机"></a>重启计算机</h6><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># reboot</span><br></code></pre></td></tr></table></figure>

<h4 id="安装图形界面"><a href="#安装图形界面" class="headerlink" title="安装图形界面"></a>安装图形界面</h4><p>使用root登入</p>
<h5 id="设置联网"><a href="#设置联网" class="headerlink" title="设置联网"></a>设置联网</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ip link<br></code></pre></td></tr></table></figure>
<p>找到网络设备, e.g. <strong>enp0s5</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ip link set enp0s3 up</span><br><span class="hljs-comment"># dhcpcd enp0s3</span><br><span class="hljs-comment"># systemctl enable dhcpcd@enp0s3.service</span><br></code></pre></td></tr></table></figure>
<p>这样使得设备自动联网</p>
<h5 id="更新软件包"><a href="#更新软件包" class="headerlink" title="更新软件包"></a>更新软件包</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># pacman -Syu</span><br></code></pre></td></tr></table></figure>
<h5 id="安装xorg"><a href="#安装xorg" class="headerlink" title="安装xorg"></a>安装xorg</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># pacman -S xorg</span><br></code></pre></td></tr></table></figure>
<p>一路默认</p>
<h5 id="安装驱动"><a href="#安装驱动" class="headerlink" title="安装驱动"></a>安装驱动</h5><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># pcaman -S xf86-video-vesa  虚拟机显卡驱动</span><br><span class="hljs-comment"># pacman -S alsa-utils 声卡驱动</span><br><span class="hljs-comment"># pacman -S xfce4 桌面套件</span><br><span class="hljs-comment"># pacman -S slim 登陆管理器</span><br><span class="hljs-comment"># pacman -S sudo 安装sudo</span><br><span class="hljs-comment"># pacman -S wqy-zenhei 安装中文字体</span><br><span class="hljs-comment"># useradd -m -s /bin/bash arch 添加一个普通用户"arch"</span><br><span class="hljs-comment"># passwd arch 设定密码</span><br><span class="hljs-comment"># visudo 为刚才添加的普通用户添加sudo的相关权限</span><br></code></pre></td></tr></table></figure>
<p><img src="/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/3.png" alt="adduser1"><br><img src="/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/4.png" alt="adduser2"><br>使用的是vi，自行查看vi的操作方法。<br>修改完:wq<br>新建.xinitrc</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#touch ~/.xinitrc</span><br></code></pre></td></tr></table></figure>
<p>内容如下<br><img src="/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/5.png" alt="xinitrc"><br>添加执行权限<br>设置自动启动slim登陆器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># sudo chmod +x ~/.xinitrc</span><br><span class="hljs-comment"># sudo systemctl enable slim.service</span><br></code></pre></td></tr></table></figure>
<p>然后reboot</p>
<h4 id="进入图形化界面"><a href="#进入图形化界面" class="headerlink" title="进入图形化界面"></a>进入图形化界面</h4><p><img src="/2019/03/22/Arch-Linux-%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/6.png" alt="GraphicalInterface"></p>
<h3 id="基本工作完成"><a href="#基本工作完成" class="headerlink" title="基本工作完成"></a>基本工作完成</h3><h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>相较于其他自带图形化界面的发行版来说，安装是硬核了点，但是给予了用户更大的自由度。<br>适合喜欢折腾的用户。<br>最后看到图像化界面后感觉还挺爽hhh…</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ArchLinux</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
</search>
